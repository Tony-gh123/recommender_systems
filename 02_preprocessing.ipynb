{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ea5d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import kagglehub\n",
    "\n",
    "from pathlib import Path\n",
    "from scipy import sparse\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import joblib\n",
    "\n",
    "import sys\n",
    "# Add src directory to python path\n",
    "if str(Path.cwd()) not in sys.path:\n",
    "    sys.path.append(str(Path.cwd()))\n",
    "\n",
    "from src.paper_protocol import make_leave_one_out_purchase_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52303076",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ffa01b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "rng = np.random.default_rng(RANDOM_SEED)\n",
    "\n",
    "# Define file paths\n",
    "RAW_EVENTS_PATH = Path(\"data/raw/events.csv\")\n",
    "CLEAN_EVENTS_PATH = Path(\"data/processed/clean_events.parquet\")\n",
    "DATA_OUT = Path(\"data/processed\")\n",
    "DATA_OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Define configuration settings\n",
    "SUPPORTED_EVENTS = {\"view\", \"addtocart\", \"transaction\"}\n",
    "event_weight = {\"view\": 1.0, \"addtocart\": 3.0, \"transaction\": 10.0}\n",
    "\n",
    "min_user_events_for_cf = 3     # set to 5+ for stronger filtering\n",
    "min_item_events = 1            # set to 2+ if you want to drop ultra-rare items\n",
    "cap_user_item_strength = 20.0  # caps repeated interactions\n",
    "\n",
    "split_strategy = \"loo\"            # \"loo\" (Leave-One-Out)\n",
    "\n",
    "neg_k = 100                       # negatives per positive for ranking eval\n",
    "eval_one_positive_per_user = True # keeps eval candidate sets lightweight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b2be2b",
   "metadata": {},
   "source": [
    "# 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57ceefbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw events not found locally. Downloading via kagglehub...\n",
      "Loading raw events from: C:\\Users\\ayera\\.cache\\kagglehub\\datasets\\retailrocket\\ecommerce-dataset\\versions\\2\\events.csv\n",
      "Raw shape: (2756101, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>visitorid</th>\n",
       "      <th>event</th>\n",
       "      <th>itemid</th>\n",
       "      <th>transactionid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1433221332117</td>\n",
       "      <td>257597</td>\n",
       "      <td>view</td>\n",
       "      <td>355908</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1433224214164</td>\n",
       "      <td>992329</td>\n",
       "      <td>view</td>\n",
       "      <td>248676</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1433221999827</td>\n",
       "      <td>111016</td>\n",
       "      <td>view</td>\n",
       "      <td>318965</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1433221955914</td>\n",
       "      <td>483717</td>\n",
       "      <td>view</td>\n",
       "      <td>253185</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1433221337106</td>\n",
       "      <td>951259</td>\n",
       "      <td>view</td>\n",
       "      <td>367447</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       timestamp  visitorid event  itemid  transactionid\n",
       "0  1433221332117     257597  view  355908           <NA>\n",
       "1  1433224214164     992329  view  248676           <NA>\n",
       "2  1433221999827     111016  view  318965           <NA>\n",
       "3  1433221955914     483717  view  253185           <NA>\n",
       "4  1433221337106     951259  view  367447           <NA>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load raw data\n",
    "# Download dataset if not found locally\n",
    "if not RAW_EVENTS_PATH.exists():\n",
    "    print(\"Raw events not found locally. Downloading via kagglehub...\")\n",
    "    kaggle_path = Path(kagglehub.dataset_download(\"retailrocket/ecommerce-dataset\"))\n",
    "    raw_source_path = kaggle_path / \"events.csv\"\n",
    "    props1_path = kaggle_path / \"item_properties_part1.csv\"\n",
    "    props2_path = kaggle_path / \"item_properties_part2.csv\"\n",
    "else:\n",
    "    raw_source_path = RAW_EVENTS_PATH\n",
    "    props1_path = Path(\"data/raw/item_properties_part1.csv\")\n",
    "    props2_path = Path(\"data/raw/item_properties_part2.csv\")\n",
    "    \n",
    "    # Fallback if props are missing locally\n",
    "    if not (props1_path.exists() and props2_path.exists()):\n",
    "        print(\"Item properties not found locally. Downloading via kagglehub...\")\n",
    "        kaggle_path = Path(kagglehub.dataset_download(\"retailrocket/ecommerce-dataset\"))\n",
    "        props1_path = kaggle_path / \"item_properties_part1.csv\"\n",
    "        props2_path = kaggle_path / \"item_properties_part2.csv\"\n",
    "\n",
    "print(f\"Loading raw events from: {raw_source_path}\")\n",
    "\n",
    "dtypes = {\n",
    "    \"timestamp\": \"int64\",\n",
    "    \"visitorid\": \"Int64\",\n",
    "    \"itemid\": \"Int64\",\n",
    "    \"event\": \"string\",\n",
    "    \"transactionid\": \"Int64\",\n",
    "}\n",
    "events = pd.read_csv(raw_source_path, dtype=dtypes)\n",
    "print(\"Raw shape:\", events.shape)\n",
    "events.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac8f120",
   "metadata": {},
   "source": [
    "# 2. Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd29e24e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 460 duplicates\n",
      "Cleaned shape: (2755641, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>visitorid</th>\n",
       "      <th>event</th>\n",
       "      <th>itemid</th>\n",
       "      <th>transactionid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-06-02 05:02:12.117000+00:00</td>\n",
       "      <td>257597</td>\n",
       "      <td>view</td>\n",
       "      <td>355908</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-06-02 05:50:14.164000+00:00</td>\n",
       "      <td>992329</td>\n",
       "      <td>view</td>\n",
       "      <td>248676</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-06-02 05:13:19.827000+00:00</td>\n",
       "      <td>111016</td>\n",
       "      <td>view</td>\n",
       "      <td>318965</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-06-02 05:12:35.914000+00:00</td>\n",
       "      <td>483717</td>\n",
       "      <td>view</td>\n",
       "      <td>253185</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-06-02 05:02:17.106000+00:00</td>\n",
       "      <td>951259</td>\n",
       "      <td>view</td>\n",
       "      <td>367447</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         timestamp  visitorid event  itemid  transactionid\n",
       "0 2015-06-02 05:02:12.117000+00:00     257597  view  355908           <NA>\n",
       "1 2015-06-02 05:50:14.164000+00:00     992329  view  248676           <NA>\n",
       "2 2015-06-02 05:13:19.827000+00:00     111016  view  318965           <NA>\n",
       "3 2015-06-02 05:12:35.914000+00:00     483717  view  253185           <NA>\n",
       "4 2015-06-02 05:02:17.106000+00:00     951259  view  367447           <NA>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean data\n",
    "# Remove rows with missing key values\n",
    "required_cols = [\"visitorid\", \"itemid\", \"timestamp\", \"event\"]\n",
    "events = events.dropna(subset=required_cols)\n",
    "\n",
    "# Convert timestamps to UTC datetime\n",
    "# RetailRocket timestamps are in milliseconds\n",
    "events[\"timestamp\"] = pd.to_datetime(events[\"timestamp\"], unit=\"ms\", utc=True, errors=\"coerce\")\n",
    "events = events.dropna(subset=[\"timestamp\"])\n",
    "\n",
    "# Keep only supported event types\n",
    "events[\"event\"] = events[\"event\"].astype(str).str.lower()\n",
    "events = events[events[\"event\"].isin(SUPPORTED_EVENTS)]\n",
    "\n",
    "# Cast columns to correct data types\n",
    "events[\"visitorid\"] = events[\"visitorid\"].astype(\"int64\")\n",
    "events[\"itemid\"] = events[\"itemid\"].astype(\"int64\")\n",
    "if \"transactionid\" in events.columns:\n",
    "    events[\"transactionid\"] = events[\"transactionid\"].astype(\"Int64\")\n",
    "\n",
    "# Remove duplicate events\n",
    "before_dedupe = len(events)\n",
    "events = events.drop_duplicates(subset=[\"visitorid\", \"itemid\", \"timestamp\", \"event\"])\n",
    "print(f\"Dropped {before_dedupe - len(events)} duplicates\")\n",
    "\n",
    "print(\"Cleaned shape:\", events.shape)\n",
    "events.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a5dce3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned events to data\\processed\\clean_events.parquet\n"
     ]
    }
   ],
   "source": [
    "# Save cleaned data to parquet\n",
    "CLEAN_EVENTS_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "events.to_parquet(CLEAN_EVENTS_PATH, index=False)\n",
    "print(f\"Saved cleaned events to {CLEAN_EVENTS_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7093056f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_events: 2755641\n",
      "n_users: 1407580 n_items: 235061\n",
      "timestamp min/max: 2015-05-03 03:00:04.384000+00:00 2015-09-18 02:59:47.788000+00:00\n",
      "event counts:\n",
      " event\n",
      "view           2664218\n",
      "addtocart        68966\n",
      "transaction      22457\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>visitorid</th>\n",
       "      <th>event</th>\n",
       "      <th>itemid</th>\n",
       "      <th>transactionid</th>\n",
       "      <th>ts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-06-02 05:02:12.117000+00:00</td>\n",
       "      <td>257597</td>\n",
       "      <td>view</td>\n",
       "      <td>355908</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2015-06-02 05:02:12.117000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-06-02 05:50:14.164000+00:00</td>\n",
       "      <td>992329</td>\n",
       "      <td>view</td>\n",
       "      <td>248676</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2015-06-02 05:50:14.164000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-06-02 05:13:19.827000+00:00</td>\n",
       "      <td>111016</td>\n",
       "      <td>view</td>\n",
       "      <td>318965</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2015-06-02 05:13:19.827000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-06-02 05:12:35.914000+00:00</td>\n",
       "      <td>483717</td>\n",
       "      <td>view</td>\n",
       "      <td>253185</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2015-06-02 05:12:35.914000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-06-02 05:02:17.106000+00:00</td>\n",
       "      <td>951259</td>\n",
       "      <td>view</td>\n",
       "      <td>367447</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2015-06-02 05:02:17.106000+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         timestamp  visitorid event  itemid  transactionid  \\\n",
       "0 2015-06-02 05:02:12.117000+00:00     257597  view  355908           <NA>   \n",
       "1 2015-06-02 05:50:14.164000+00:00     992329  view  248676           <NA>   \n",
       "2 2015-06-02 05:13:19.827000+00:00     111016  view  318965           <NA>   \n",
       "3 2015-06-02 05:12:35.914000+00:00     483717  view  253185           <NA>   \n",
       "4 2015-06-02 05:02:17.106000+00:00     951259  view  367447           <NA>   \n",
       "\n",
       "                                ts  \n",
       "0 2015-06-02 05:02:12.117000+00:00  \n",
       "1 2015-06-02 05:50:14.164000+00:00  \n",
       "2 2015-06-02 05:13:19.827000+00:00  \n",
       "3 2015-06-02 05:12:35.914000+00:00  \n",
       "4 2015-06-02 05:02:17.106000+00:00  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create short timestamp column\n",
    "events[\"ts\"] = events[\"timestamp\"]\n",
    "\n",
    "# Print dataset statistics\n",
    "print(\"n_events:\", len(events))\n",
    "print(\"n_users:\", events[\"visitorid\"].nunique(), \"n_items:\", events[\"itemid\"].nunique())\n",
    "print(\"timestamp min/max:\", events[\"timestamp\"].min(), events[\"timestamp\"].max())\n",
    "print(\"event counts:\\n\", events[\"event\"].value_counts())\n",
    "\n",
    "required_cols = [\"visitorid\",\"itemid\",\"event\",\"timestamp\"]\n",
    "for col in required_cols:\n",
    "    assert col in events.columns, f\"Missing required column {col}\"\n",
    "events.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc2448f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>visitorid</th>\n",
       "      <th>itemid</th>\n",
       "      <th>event</th>\n",
       "      <th>transactionid</th>\n",
       "      <th>ts</th>\n",
       "      <th>w</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>285930</td>\n",
       "      <td>view</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2015-09-11 20:49:49.439000+00:00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>357564</td>\n",
       "      <td>view</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2015-09-11 20:52:39.591000+00:00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>67045</td>\n",
       "      <td>view</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2015-09-11 20:55:17.175000+00:00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>72028</td>\n",
       "      <td>view</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2015-08-13 17:46:06.444000+00:00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>325215</td>\n",
       "      <td>view</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2015-08-07 17:51:44.567000+00:00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   visitorid  itemid event  transactionid                               ts  \\\n",
       "0          0  285930  view           <NA> 2015-09-11 20:49:49.439000+00:00   \n",
       "1          0  357564  view           <NA> 2015-09-11 20:52:39.591000+00:00   \n",
       "2          0   67045  view           <NA> 2015-09-11 20:55:17.175000+00:00   \n",
       "3          1   72028  view           <NA> 2015-08-13 17:46:06.444000+00:00   \n",
       "4          2  325215  view           <NA> 2015-08-07 17:51:44.567000+00:00   \n",
       "\n",
       "     w  \n",
       "0  1.0  \n",
       "1  1.0  \n",
       "2  1.0  \n",
       "3  1.0  \n",
       "4  1.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort events by user and time\n",
    "events = events.sort_values([\"visitorid\", \"ts\", \"itemid\"]).reset_index(drop=True)\n",
    "\n",
    "# Assign weights to event types\n",
    "events[\"w\"] = events[\"event\"].astype(str).map(event_weight).astype(\"float32\")\n",
    "\n",
    "events[[\"visitorid\",\"itemid\",\"event\",\"transactionid\",\"ts\",\"w\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c866a970",
   "metadata": {},
   "source": [
    "# 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d1314f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agg rows: 2145179 | unique users: 1407580 | unique items: 235061\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>visitorid</th>\n",
       "      <th>itemid</th>\n",
       "      <th>ts_last</th>\n",
       "      <th>w_sum</th>\n",
       "      <th>w_max</th>\n",
       "      <th>n_events</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>67045</td>\n",
       "      <td>2015-09-11 20:55:17.175000+00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>285930</td>\n",
       "      <td>2015-09-11 20:49:49.439000+00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>357564</td>\n",
       "      <td>2015-09-11 20:52:39.591000+00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>72028</td>\n",
       "      <td>2015-08-13 17:46:06.444000+00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>216305</td>\n",
       "      <td>2015-08-07 18:17:43.170000+00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   visitorid  itemid                          ts_last  w_sum  w_max  n_events\n",
       "0          0   67045 2015-09-11 20:55:17.175000+00:00    1.0    1.0         1\n",
       "1          0  285930 2015-09-11 20:49:49.439000+00:00    1.0    1.0         1\n",
       "2          0  357564 2015-09-11 20:52:39.591000+00:00    1.0    1.0         1\n",
       "3          1   72028 2015-08-13 17:46:06.444000+00:00    1.0    1.0         1\n",
       "4          2  216305 2015-08-07 18:17:43.170000+00:00    2.0    1.0         2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aggregate events by user and item\n",
    "agg = (events\n",
    "    .groupby([\"visitorid\",\"itemid\"], as_index=False)\n",
    "    .agg(\n",
    "        ts_last=(\"ts\",\"max\"),\n",
    "        w_sum=(\"w\",\"sum\"),\n",
    "        w_max=(\"w\",\"max\"),\n",
    "        n_events=(\"w\",\"size\"),\n",
    "    ))\n",
    "\n",
    "agg[\"w_sum\"] = agg[\"w_sum\"].clip(upper=cap_user_item_strength).astype(\"float32\")\n",
    "agg[\"w_max\"] = agg[\"w_max\"].astype(\"float32\")\n",
    "\n",
    "print(\"agg rows:\", len(agg), \"| unique users:\", agg[\"visitorid\"].nunique(), \"| unique items:\", agg[\"itemid\"].nunique())\n",
    "agg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a756c15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter items by minimum events\n",
    "if min_item_events > 1:\n",
    "    item_counts = agg[\"itemid\"].value_counts()\n",
    "    keep_items = set(item_counts[item_counts >= min_item_events].index)\n",
    "    agg = agg[agg[\"itemid\"].isin(keep_items)].copy()\n",
    "    print(\"after MIN_ITEM_EVENTS filter:\", agg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a1e7cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agg total: (2145179, 6)\n",
      "agg_cf (active users): (684577, 6)\n"
     ]
    }
   ],
   "source": [
    "# Filter users by minimum events\n",
    "user_counts = agg[\"visitorid\"].value_counts()\n",
    "active_users = set(user_counts[user_counts >= min_user_events_for_cf].index)\n",
    "\n",
    "agg_cf = agg[agg[\"visitorid\"].isin(active_users)].copy()\n",
    "\n",
    "print(\"agg total:\", agg.shape)\n",
    "print(\"agg_cf (active users):\", agg_cf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5f6de9",
   "metadata": {},
   "source": [
    "# 4. Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f883f16d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Multi-Behavior Leave-One-Out Protocol (Target: Purchase)...\n",
      "Users with >= 3 transactions: 1027\n",
      "Users with >= 2 transactions: 2576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1027/1027 [00:02<00:00, 371.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split sizes (events): Train=105653, Val=1027, Test=1027\n",
      "Aggregating train events...\n",
      "train/val/test (aggregated shapes): (59659, 6) (1027, 6) (1027, 6)\n"
     ]
    }
   ],
   "source": [
    "print(\"Using Multi-Behavior Leave-One-Out Protocol (Target: Purchase)...\")\n",
    "\n",
    "# Count transactions per user\n",
    "trans_counts = events[events[\"event\"] == \"transaction\"][\"visitorid\"].value_counts()\n",
    "print(f\"Users with >= 3 transactions: {(trans_counts >= 3).sum()}\")\n",
    "print(f\"Users with >= 2 transactions: {(trans_counts >= 2).sum()}\")\n",
    "\n",
    "# Split data using Leave-One-Out strategy\n",
    "train_events, val_events, test_events = make_leave_one_out_purchase_splits(events, min_interactions=3)\n",
    "\n",
    "print(f\"Split sizes (events): Train={len(train_events)}, Val={len(val_events)}, Test={len(test_events)}\")\n",
    "\n",
    "# Aggregate events by user and item\n",
    "def aggregate_events(df):\n",
    "    # df already has 'w' column from previous cells\n",
    "    agg = df.groupby([\"visitorid\", \"itemid\"]).agg(\n",
    "        ts_last=(\"ts\", \"max\"),\n",
    "        w_sum=(\"w\", \"sum\"),\n",
    "        w_max=(\"w\", \"max\"),\n",
    "        n_events=(\"event\", \"count\")\n",
    "    ).reset_index()\n",
    "    return agg\n",
    "\n",
    "print(\"Aggregating train events...\")\n",
    "train = aggregate_events(train_events)\n",
    "val = aggregate_events(val_events)\n",
    "test = aggregate_events(test_events)\n",
    "\n",
    "print(\"train/val/test (aggregated shapes):\", train.shape, val.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b430c544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val/test after train-only filter: (794, 6) (814, 6)\n"
     ]
    }
   ],
   "source": [
    "# Filter validation and test sets\n",
    "train_users = set(train[\"visitorid\"].unique())\n",
    "train_items = set(train[\"itemid\"].unique())\n",
    "\n",
    "val  = val[val[\"visitorid\"].isin(train_users) & val[\"itemid\"].isin(train_items)].copy()\n",
    "test = test[test[\"visitorid\"].isin(train_users) & test[\"itemid\"].isin(train_items)].copy()\n",
    "\n",
    "print(\"val/test after train-only filter:\", val.shape, test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d943d5e",
   "metadata": {},
   "source": [
    "# 5. Create Mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8346451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_users: 984 n_items: 25479\n"
     ]
    }
   ],
   "source": [
    "# Create user and item mappings\n",
    "unique_users = np.array(sorted(train[\"visitorid\"].unique()))\n",
    "unique_items = np.array(sorted(train[\"itemid\"].unique()))\n",
    "\n",
    "user2idx = {int(u): int(i) for i, u in enumerate(unique_users)}\n",
    "item2idx = {int(it): int(i) for i, it in enumerate(unique_items)}\n",
    "\n",
    "with open(DATA_OUT / \"user2idx.json\", \"w\") as f:\n",
    "    json.dump(user2idx, f)\n",
    "with open(DATA_OUT / \"item2idx.json\", \"w\") as f:\n",
    "    json.dump(item2idx, f)\n",
    "\n",
    "print(\"n_users:\", len(user2idx), \"n_items:\", len(item2idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a52d1626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>visitorid</th>\n",
       "      <th>itemid</th>\n",
       "      <th>ts_last</th>\n",
       "      <th>w_sum</th>\n",
       "      <th>w_max</th>\n",
       "      <th>n_events</th>\n",
       "      <th>u</th>\n",
       "      <th>i</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3465</td>\n",
       "      <td>8523</td>\n",
       "      <td>2015-06-16 01:34:15.600000+00:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3926</td>\n",
       "      <td>36039</td>\n",
       "      <td>2015-06-17 00:33:53.859000+00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3926</td>\n",
       "      <td>335331</td>\n",
       "      <td>2015-06-02 20:01:56.963000+00:00</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>18298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4101</td>\n",
       "      <td>104752</td>\n",
       "      <td>2015-05-21 00:32:25.232000+00:00</td>\n",
       "      <td>14.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4101</td>\n",
       "      <td>115244</td>\n",
       "      <td>2015-05-21 00:25:10.185000+00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6288</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   visitorid  itemid                          ts_last  w_sum  w_max  n_events  \\\n",
       "0       3465    8523 2015-06-16 01:34:15.600000+00:00    4.0    3.0         2   \n",
       "1       3926   36039 2015-06-17 00:33:53.859000+00:00    2.0    1.0         2   \n",
       "2       3926  335331 2015-06-02 20:01:56.963000+00:00   12.0   10.0         3   \n",
       "3       4101  104752 2015-05-21 00:32:25.232000+00:00   14.0   10.0         3   \n",
       "4       4101  115244 2015-05-21 00:25:10.185000+00:00    2.0    1.0         2   \n",
       "\n",
       "   u      i  \n",
       "0  0    437  \n",
       "1  1   1917  \n",
       "2  1  18298  \n",
       "3  2   5729  \n",
       "4  2   6288  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_indices(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Add internal indices to dataframe\n",
    "    df = df.copy()\n",
    "    df[\"u\"] = df[\"visitorid\"].map(user2idx)\n",
    "    df[\"i\"] = df[\"itemid\"].map(item2idx)\n",
    "    # keep ts_last for later (eval filtering / last interaction)\n",
    "    return df.dropna(subset=[\"u\",\"i\"]).astype({\"u\":\"int32\",\"i\":\"int32\"})\n",
    "\n",
    "# Add indices to train, val, test\n",
    "train_i = add_indices(train)\n",
    "val_i   = add_indices(val)\n",
    "test_i  = add_indices(test)\n",
    "\n",
    "train_i.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00743591",
   "metadata": {},
   "source": [
    "# 6. Build Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "069140ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (984, 25479) nnz: 59659\n"
     ]
    }
   ],
   "source": [
    "def build_csr(df: pd.DataFrame, n_users: int, n_items: int, weight_col=\"w_sum\"):\n",
    "    # Build CSR matrix\n",
    "    rows = df[\"u\"].to_numpy()\n",
    "    cols = df[\"i\"].to_numpy()\n",
    "    data = df[weight_col].to_numpy(dtype=np.float32)\n",
    "    X = sparse.csr_matrix((data, (rows, cols)), shape=(n_users, n_items))\n",
    "    X.sum_duplicates()\n",
    "    return X\n",
    "\n",
    "# Build and save CSR matrix\n",
    "X_train = build_csr(train_i, len(user2idx), len(item2idx), weight_col=\"w_sum\")\n",
    "sparse.save_npz(DATA_OUT / \"X_train_csr.npz\", X_train)\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape, \"nnz:\", X_train.nnz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "971e5ea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemid</th>\n",
       "      <th>pop</th>\n",
       "      <th>i</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1331</th>\n",
       "      <td>119736</td>\n",
       "      <td>89</td>\n",
       "      <td>6527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2425</th>\n",
       "      <td>213834</td>\n",
       "      <td>31</td>\n",
       "      <td>11661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5250</th>\n",
       "      <td>461686</td>\n",
       "      <td>28</td>\n",
       "      <td>25184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2834</th>\n",
       "      <td>248455</td>\n",
       "      <td>17</td>\n",
       "      <td>13542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3579</th>\n",
       "      <td>312728</td>\n",
       "      <td>16</td>\n",
       "      <td>17100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3652</th>\n",
       "      <td>320130</td>\n",
       "      <td>15</td>\n",
       "      <td>17489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4221</th>\n",
       "      <td>369158</td>\n",
       "      <td>14</td>\n",
       "      <td>20215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4785</th>\n",
       "      <td>420960</td>\n",
       "      <td>13</td>\n",
       "      <td>23036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>17478</td>\n",
       "      <td>13</td>\n",
       "      <td>910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3791</th>\n",
       "      <td>334401</td>\n",
       "      <td>13</td>\n",
       "      <td>18239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      itemid  pop      i\n",
       "1331  119736   89   6527\n",
       "2425  213834   31  11661\n",
       "5250  461686   28  25184\n",
       "2834  248455   17  13542\n",
       "3579  312728   16  17100\n",
       "3652  320130   15  17489\n",
       "4221  369158   14  20215\n",
       "4785  420960   13  23036\n",
       "185    17478   13    910\n",
       "3791  334401   13  18239"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate item popularity based on TRANSACTIONS only (to match negative sampling and LOO target)\n",
    "train_purchases = train_events[train_events[\"event\"] == \"transaction\"]\n",
    "\n",
    "item_pop = (train_purchases.groupby(\"itemid\")\n",
    "            .size()\n",
    "            .reset_index(name=\"pop\")\n",
    "            .sort_values(\"pop\", ascending=False))\n",
    "\n",
    "# Map item IDs to internal indices\n",
    "item_pop[\"i\"] = item_pop[\"itemid\"].map(item2idx)\n",
    "# Filter items not in training set\n",
    "item_pop = item_pop.dropna(subset=[\"i\"]).astype({\"i\": \"int32\"})\n",
    "\n",
    "item_pop.to_parquet(DATA_OUT / \"item_popularity.parquet\", index=False)\n",
    "item_pop.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7a07c5",
   "metadata": {},
   "source": [
    "# 7. Process Item Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22afa7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_cutoff: 2015-09-18 02:34:21.089000+00:00\n",
      "keep_itemids: 25479\n",
      "item_props snapshot rows: 711102\n",
      "unique items in snapshot: 24455\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemid</th>\n",
       "      <th>property</th>\n",
       "      <th>value</th>\n",
       "      <th>ts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>323093</td>\n",
       "      <td>112</td>\n",
       "      <td>679677</td>\n",
       "      <td>2015-05-10 03:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21899</td>\n",
       "      <td>364</td>\n",
       "      <td>816290</td>\n",
       "      <td>2015-05-10 03:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>128318</td>\n",
       "      <td>71</td>\n",
       "      <td>376905</td>\n",
       "      <td>2015-05-10 03:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>444323</td>\n",
       "      <td>678</td>\n",
       "      <td>1290827</td>\n",
       "      <td>2015-05-10 03:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>255622</td>\n",
       "      <td>776</td>\n",
       "      <td>577331</td>\n",
       "      <td>2015-05-10 03:00:00+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   itemid property    value                        ts\n",
       "0  323093      112   679677 2015-05-10 03:00:00+00:00\n",
       "1   21899      364   816290 2015-05-10 03:00:00+00:00\n",
       "2  128318       71   376905 2015-05-10 03:00:00+00:00\n",
       "3  444323      678  1290827 2015-05-10 03:00:00+00:00\n",
       "4  255622      776   577331 2015-05-10 03:00:00+00:00"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def iter_item_props(paths, chunksize=5_000_000):\n",
    "    # Iterate over item properties\n",
    "    # Explicitly setting dtypes saves memory and ensures correct parsing\n",
    "    dtypes = {\"timestamp\":\"int64\", \"itemid\":\"int64\", \"property\":\"string\", \"value\":\"string\"}\n",
    "    for p in paths:\n",
    "        for chunk in pd.read_csv(p, dtype=dtypes, chunksize=chunksize):\n",
    "            chunk[\"ts\"] = pd.to_datetime(chunk[\"timestamp\"], unit=\"ms\", utc=True)\n",
    "            yield chunk\n",
    "\n",
    "# For LOO, prevent leakage by capping at the last training event\n",
    "train_cutoff = train_events[\"ts\"].max()\n",
    "\n",
    "keep_itemids = set(item2idx.keys())\n",
    "\n",
    "print(\"train_cutoff:\", train_cutoff)\n",
    "print(\"keep_itemids:\", len(keep_itemids))\n",
    "\n",
    "latest_rows = []\n",
    "for chunk in iter_item_props([props1_path, props2_path], chunksize=5_000_000):\n",
    "    chunk = chunk[chunk[\"itemid\"].isin(keep_itemids)]\n",
    "    if train_cutoff is not None:\n",
    "        chunk = chunk[chunk[\"ts\"] <= train_cutoff]\n",
    "\n",
    "    # Keep latest property value per item\n",
    "    chunk = chunk.sort_values(\"ts\").drop_duplicates([\"itemid\",\"property\"], keep=\"last\")\n",
    "    latest_rows.append(chunk[[\"itemid\",\"property\",\"value\",\"ts\"]])\n",
    "\n",
    "item_props = pd.concat(latest_rows, ignore_index=True)\n",
    "# Deduplicate properties across chunks\n",
    "item_props = (item_props.sort_values(\"ts\")\n",
    "              .drop_duplicates([\"itemid\",\"property\"], keep=\"last\")\n",
    "              .reset_index(drop=True))\n",
    "\n",
    "print(\"item_props snapshot rows:\", len(item_props))\n",
    "print(\"unique items in snapshot:\", item_props[\"itemid\"].nunique())\n",
    "item_props.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8cb09296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_text rows (should equal n_items): 25479\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemid</th>\n",
       "      <th>token</th>\n",
       "      <th>i</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>pcategoryid=v722 p764=v1285872 p917=v789221 p3...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>p917=vn58500.000 p764=v1285872 p790=vn27120.00...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>p678=v743822_552121 p283=v984060_150169_103789...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>p159=v519769 p112=v679677 p364=v316529 p917=vn...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>p776=v905905 p6=v1285402_1042990 p159=v519769 ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   itemid                                              token  i\n",
       "0      15  pcategoryid=v722 p764=v1285872 p917=v789221 p3...  0\n",
       "1      17  p917=vn58500.000 p764=v1285872 p790=vn27120.00...  1\n",
       "2      19  p678=v743822_552121 p283=v984060_150169_103789...  2\n",
       "3      25  p159=v519769 p112=v679677 p364=v316529 p917=vn...  3\n",
       "4      42  p776=v905905 p6=v1285402_1042990 p159=v519769 ...  4"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Process item properties\n",
    "item_props[\"value\"] = item_props[\"value\"].fillna(\"\").astype(str)\n",
    "item_props[\"value\"] = item_props[\"value\"].str.replace(r\"\\s+\", \"_\", regex=True)\n",
    "\n",
    "item_props[\"token\"] = \"p\" + item_props[\"property\"].astype(str) + \"=v\" + item_props[\"value\"]\n",
    "\n",
    "item_text = (item_props.groupby(\"itemid\")[\"token\"]\n",
    "             .apply(lambda s: \" \".join(s.values))\n",
    "             .reset_index())\n",
    "\n",
    "# Ensure all training items have property entries\n",
    "all_items_df = pd.DataFrame({\"itemid\": list(keep_itemids)})\n",
    "item_text = all_items_df.merge(item_text, on=\"itemid\", how=\"left\")\n",
    "item_text[\"token\"] = item_text[\"token\"].fillna(\"\")\n",
    "\n",
    "# Sort by internal item index\n",
    "item_text[\"i\"] = item_text[\"itemid\"].map(item2idx)\n",
    "item_text = item_text.sort_values(\"i\").reset_index(drop=True)\n",
    "\n",
    "print(\"item_text rows (should equal n_items):\", len(item_text))\n",
    "item_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "235f7580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample tokens: ['pcategoryid=v722 p764=v1285872 p917=v789221 p364=v1047026 p283=v433564_245772_789221_809278_245772_1213953_429140_1322984_792235_79212_237874_654986_809278_1215254_249416_646928_750061_961877_1152409_780700_1128577_269926_754848_703408_469750_581854_1028919_1124417_484436_1256252_790607 p678=v245772 p915=v769062 p202=v789221 p698=v433564 p616=v769062 p888=v789221 p839=v245772 p227=v433564 p159=v519769 p812=v769062 p112=v679677 p693=v769062 p776=v604754 p790=vn8400.000 p591=v1116693 pavailable=v0', 'p917=vn58500.000 p764=v1285872 p790=vn27120.000 p159=v519769 p6=v245617 p283=v245617_365855_1263472_n58500.000 p776=v840531 p364=v1083699 pcategoryid=v1265 p839=v365855 p202=v1263472_n58500.000 pavailable=v0 p888=v1263472_n58500.000 p348=v245617 p392=v706848 p678=v365855 p112=v679677 p227=v245617', 'p678=v743822_552121 p283=v984060_150169_1037891_743822_552121_119805 p888=v119805 p6=v353870_1310600 p917=v119805 p604=v769062 p764=v1285872 p562=v769062_639502_n278.400_1041241_913084 p459=v769062 p227=v353870_1310600 pcategoryid=v1171 p112=v679677 p453=v769062 p202=v119805 p364=v779779 p776=v601927 p30=v769062 p33=v279887_421694 p839=v743822_552121 p658=vn24000.000_21263 p698=v353870_1310600 p159=v519769 p250=v300154 p1025=vn399.360_357845_903043 p689=v150169_1037891 p326=v914000 p1080=v769062 pavailable=v1 p790=vn19800.000', 'p159=v519769 p112=v679677 p364=v316529 p917=vn1092.000_15252 p6=v1272323 p678=v273987 p839=v273987 p348=v1272323 p675=vn60.000 p720=vn14400.000_10317 p105=v769062 p776=v1148452 p227=v1272323 p283=v1272323_273987_418093_1231777_273987_418093_413151_283006_493397_1244358_1195475_1128577_901561_988697_5041_40042_285545_312815_859787_1272323_30603_519647_1116693_1215254_1308676_1256774_42114_30603_642930_1273286_484436_30603_1044181_634180_30603_180703_653611_880027_989819 p28=v150169_274770_79212 p764=v1285872 p409=v375939 p591=v1116693 p1036=v1154859 p1077=v140221 p202=v418093_1231777 p888=v418093_1231777_1154859 p790=vn45600.000 pavailable=v1 pcategoryid=v72', 'p776=v905905 p6=v1285402_1042990 p159=v519769 p283=v1285402_1042990_362953_731607_73247 p227=v1285402_1042990 p678=v731607 pcategoryid=v84 p764=v1285872 p917=v416868_1107526 p112=v679677 p899=v362953 p457=v535067 p1036=v726612 p566=vn600.000_424566 p839=v731607 p230=v1096229 p202=v73247 p698=v1285402_1042990 p348=v530843 p364=v91866 p993=v881499 p1066=vn68.400_424566 p1052=v1116693 p327=v530843 p900=vn696.000_424566 p62=v530843 p728=v227347_1277294 p617=v362953 p928=v726612 p591=v1116693 p790=vn279480.000 p888=v73247_726612 pavailable=v1 p400=vn552.000_639502_n720.000_424566']\n",
      "Empty tokens count: 1024\n",
      "Total items: 25479\n",
      "X_item shape: (25479, 20122) nnz: 558243\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample tokens:\", item_text[\"token\"].head().tolist())\n",
    "print(\"Empty tokens count:\", (item_text[\"token\"] == \"\").sum())\n",
    "print(\"Total items:\", len(item_text))\n",
    "\n",
    "try:\n",
    "    # Create TF-IDF matrix\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        token_pattern=r\"[^ ]+\",\n",
    "        min_df=2,\n",
    "        max_features=200_000,\n",
    "        dtype=np.float32\n",
    "    )\n",
    "    X_item = vectorizer.fit_transform(item_text[\"token\"].values)\n",
    "except ValueError:\n",
    "    print(\"Warning: min_df=2 failed (likely too sparse or empty). Retrying with min_df=1...\")\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        token_pattern=r\"[^ ]+\",\n",
    "        min_df=1,\n",
    "        max_features=200_000,\n",
    "        dtype=np.float32\n",
    "    )\n",
    "    try:\n",
    "        X_item = vectorizer.fit_transform(item_text[\"token\"].values)\n",
    "    except ValueError:\n",
    "        print(\"Warning: Empty vocabulary even with min_df=1. Creating dummy features.\")\n",
    "        # Create dummy feature if vocabulary is empty\n",
    "        item_text[\"dummy\"] = \"item\"\n",
    "        vectorizer = TfidfVectorizer(token_pattern=r\"[^ ]+\", min_df=1)\n",
    "        X_item = vectorizer.fit_transform(item_text[\"dummy\"].values)\n",
    "\n",
    "sparse.save_npz(DATA_OUT / \"item_content_tfidf.npz\", X_item)\n",
    "joblib.dump(vectorizer, DATA_OUT / \"tfidf_vectorizer.joblib\")\n",
    "\n",
    "print(\"X_item shape:\", X_item.shape, \"nnz:\", X_item.nnz)\n",
    "\n",
    "# Verify TF-IDF matrix size\n",
    "assert X_item.shape[1] > 1000, f\"TF-IDF vocabulary too small ({X_item.shape[1]}). Check item properties or tokenization.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f076ab",
   "metadata": {},
   "source": [
    "# 8. Build Evaluation Candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98abbff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Popularity distribution built from 7482 purchases.\n",
      "Top 5 items: [ 6527 11661 25184 13542 17100]\n",
      "Building validation candidates...\n",
      "Building test candidates...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u</th>\n",
       "      <th>pos_i</th>\n",
       "      <th>neg_i</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>6248</td>\n",
       "      <td>[8717, 16913, 22554, 22576, 23089, 9778, 12849...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>17677</td>\n",
       "      <td>[22530, 1045, 2584, 10268, 13853, 17439, 3114,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>12435</td>\n",
       "      <td>[10241, 19461, 8200, 4618, 10253, 23, 1565, 15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>6942</td>\n",
       "      <td>[10241, 4106, 8718, 5147, 3106, 11811, 10275, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>15780</td>\n",
       "      <td>[9217, 14343, 4105, 4618, 11274, 24590, 22031,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   u  pos_i                                              neg_i\n",
       "0  0   6248  [8717, 16913, 22554, 22576, 23089, 9778, 12849...\n",
       "1  1  17677  [22530, 1045, 2584, 10268, 13853, 17439, 3114,...\n",
       "2  2  12435  [10241, 19461, 8200, 4618, 10253, 23, 1565, 15...\n",
       "3  3   6942  [10241, 4106, 8718, 5147, 3106, 11811, 10275, ...\n",
       "4  4  15780  [9217, 14343, 4105, 4618, 11274, 24590, 22031,..."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select one positive item per user for evaluation\n",
    "val_pos = val_i.copy()\n",
    "test_pos = test_i.copy()\n",
    "\n",
    "# Map users to their training items\n",
    "train_user_items = (\n",
    "    train_i.groupby(\"u\")[\"i\"].apply(lambda s: set(s.values)).to_dict()\n",
    ")\n",
    "\n",
    "# Map users to their validation items\n",
    "val_user_items = (\n",
    "    val_i.groupby(\"u\")[\"i\"].apply(lambda s: set(s.values)).to_dict()\n",
    ")\n",
    "\n",
    "# Build popularity distribution from TRAIN purchases only\n",
    "train_purchases = train_events[train_events[\"event\"] == \"transaction\"]\n",
    "# Map to internal indices\n",
    "train_purchases_i = train_purchases.copy()\n",
    "train_purchases_i[\"i\"] = train_purchases_i[\"itemid\"].map(item2idx)\n",
    "train_purchases_i = train_purchases_i.dropna(subset=[\"i\"]).astype({\"i\": \"int32\"})\n",
    "\n",
    "pop_counts = train_purchases_i[\"i\"].value_counts()\n",
    "all_items = pop_counts.index.to_numpy()\n",
    "pop_probs = (pop_counts / pop_counts.sum()).to_numpy()\n",
    "\n",
    "print(f\"Popularity distribution built from {len(train_purchases_i)} purchases.\")\n",
    "print(f\"Top 5 items: {all_items[:5]}\")\n",
    "\n",
    "def sample_negatives(u: int, k: int, split: str) -> list:\n",
    "    # Sample negative candidates\n",
    "    seen = set(train_user_items.get(u, []))\n",
    "    if split == \"test\":\n",
    "        seen.update(val_user_items.get(u, []))\n",
    "    \n",
    "    negs = set()\n",
    "    max_tries = 50000\n",
    "    tries = 0\n",
    "    \n",
    "    while len(negs) < k and tries < max_tries:\n",
    "        batch_size = (k - len(negs)) * 2\n",
    "        candidates = rng.choice(all_items, size=batch_size, p=pop_probs, replace=True)\n",
    "        for c in candidates:\n",
    "            if c not in seen:\n",
    "                negs.add(int(c))\n",
    "                if len(negs) == k:\n",
    "                    break\n",
    "        tries += 1\n",
    "        \n",
    "    if len(negs) < k:\n",
    "        # Fallback to random sampling\n",
    "        print(f\"Warning: Popularity sampling exhausted for user {u}. Falling back to random.\")\n",
    "        all_indices = np.arange(len(item2idx))\n",
    "        while len(negs) < k:\n",
    "            c = int(rng.choice(all_indices))\n",
    "            if c not in seen:\n",
    "                negs.add(c)\n",
    "                \n",
    "    return list(negs)\n",
    "\n",
    "def build_eval_candidates(df_pos: pd.DataFrame, split_name: str):\n",
    "    # Build evaluation candidates\n",
    "    rows = []\n",
    "    for r in df_pos.itertuples(index=False):\n",
    "        u = int(r.u)\n",
    "        pos_i = int(r.i)\n",
    "        \n",
    "        # Ensure positive is not in negatives\n",
    "        negs = sample_negatives(u, neg_k, split_name)\n",
    "        \n",
    "        # Sanity check\n",
    "        if pos_i in negs:\n",
    "            negs.remove(pos_i)\n",
    "            # Resample one\n",
    "            while len(negs) < neg_k:\n",
    "                c = int(rng.choice(all_items, p=pop_probs))\n",
    "                if c != pos_i and c not in negs:\n",
    "                    negs.append(c)\n",
    "\n",
    "        rows.append({\"u\": u, \"pos_i\": pos_i, \"neg_i\": negs})\n",
    "    out = pd.DataFrame(rows)\n",
    "    out.to_parquet(DATA_OUT / f\"eval_candidates_{split_name}.parquet\", index=False)\n",
    "    return out\n",
    "\n",
    "print(\"Building validation candidates...\")\n",
    "val_cand  = build_eval_candidates(val_pos, \"val\")\n",
    "print(\"Building test candidates...\")\n",
    "test_cand = build_eval_candidates(test_pos, \"test\")\n",
    "\n",
    "val_cand.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333f6c4f",
   "metadata": {},
   "source": [
    "# 9. Save Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7d5f9cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'random_seed': 42,\n",
       " 'event_weight': {'view': 1.0, 'addtocart': 3.0, 'transaction': 10.0},\n",
       " 'min_user_events_for_cf': 3,\n",
       " 'min_item_events': 1,\n",
       " 'cap_user_item_strength': 20.0,\n",
       " 'split_strategy': 'loo',\n",
       " 'neg_k': 100,\n",
       " 'eval_one_positive_per_user': True,\n",
       " 'train_cutoff_used_for_item_props': '2015-09-18 02:34:21.089000+00:00',\n",
       " 'n_users': 984,\n",
       " 'n_items': 25479,\n",
       " 'X_train_nnz': 59659,\n",
       " 'X_item_nnz': 558243}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save processed data\n",
    "train_i.to_parquet(DATA_OUT / \"interactions_train.parquet\", index=False)\n",
    "val_i.to_parquet(DATA_OUT / \"interactions_val.parquet\", index=False)\n",
    "test_i.to_parquet(DATA_OUT / \"interactions_test.parquet\", index=False)\n",
    "\n",
    "meta = {\n",
    "    \"random_seed\": RANDOM_SEED,\n",
    "    \"event_weight\": event_weight,\n",
    "    \"min_user_events_for_cf\": min_user_events_for_cf,\n",
    "    \"min_item_events\": min_item_events,\n",
    "    \"cap_user_item_strength\": cap_user_item_strength,\n",
    "    \"split_strategy\": split_strategy,\n",
    "    \"neg_k\": neg_k,\n",
    "    \"eval_one_positive_per_user\": eval_one_positive_per_user,\n",
    "    \"train_cutoff_used_for_item_props\": str(train_cutoff) if train_cutoff is not None else None,\n",
    "    \"n_users\": len(user2idx),\n",
    "    \"n_items\": len(item2idx),\n",
    "    \"X_train_nnz\": int(X_train.nnz),\n",
    "    \"X_item_nnz\": int(X_item.nnz),\n",
    "}\n",
    "\n",
    "with open(DATA_OUT / \"preprocess_metadata.json\", \"w\") as f:\n",
    "    json.dump(meta, f, indent=2)\n",
    "\n",
    "meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7a779ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train users: 984 Train items: 25479\n",
      "Val users: 794 Val items: 749\n",
      "Test users: 814 Test items: 745\n"
     ]
    }
   ],
   "source": [
    "# Verify data integrity\n",
    "print(\"Train users:\", train_i[\"u\"].nunique(), \"Train items:\", train_i[\"i\"].nunique())\n",
    "print(\"Val users:\", val_i[\"u\"].nunique(), \"Val items:\", val_i[\"i\"].nunique())\n",
    "print(\"Test users:\", test_i[\"u\"].nunique(), \"Test items:\", test_i[\"i\"].nunique())\n",
    "\n",
    "assert len(val_i) > 0 and len(test_i) > 0, \"Val/Test ended up empty after filtering — relax filters or adjust split.\"\n",
    "assert X_item.shape[0] == len(item2idx), \"Item content matrix must align to item2idx.\"\n",
    "assert X_train.shape == (len(user2idx), len(item2idx)), \"CF matrix shape mismatch.\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
